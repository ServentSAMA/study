"""
å›¾åƒå·ç§¯
"""
import torch
from torch import nn
from d2l import torch as d2l


def corr2d(X, K):
    """
    è®¡ç®—äºŒç»´äº’ç›¸å…³è¿ç®—
    âš ï¸ æ³¨æ„ï¼šæ­¤å‡½æ•°ä¸æ”¯æŒ batchã€å¤šé€šé“ã€paddingã€stride > 1ï¼Œä»…ç”¨äºæ•™å­¦æ¼”ç¤ºã€‚
    ä¸å·ç§¯çš„åŒºåˆ«
    ğŸ’¡ åœ¨ CNN ä¸­ï¼Œç”±äºå·ç§¯æ ¸æ˜¯å¯å­¦ä¹ çš„å‚æ•°ï¼Œæ˜¯å¦ç¿»è½¬å¹¶ä¸å½±å“æ¨¡å‹è¡¨è¾¾èƒ½åŠ›ï¼Œå› æ­¤æ¡†æ¶ï¼ˆå¦‚ PyTorch çš„ nn.Conv2dï¼‰å®é™…ä¸Šå®ç°çš„æ˜¯äº’ç›¸å…³ï¼Œ
        ä½†ä¹ æƒ¯ä¸Šä»ç§°ä¸ºâ€œå·ç§¯â€ã€‚
    :param X: è¾“å…¥çš„äºŒç»´å¼ é‡ï¼ˆå¦‚å•é€šé“å›¾åƒï¼‰ï¼Œå½¢çŠ¶ä¸º (H_in, W_in)
    :param K: å·ç§¯æ ¸ï¼ˆkernelï¼‰æˆ–æ»¤æ³¢å™¨ï¼ˆfilterï¼‰ï¼Œå½¢çŠ¶ä¸º (h, w)
    :return:
    """
    # è·å–å·ç§¯æ ¸å°ºå¯¸
    h, w = K.shape
    # åˆå§‹åŒ–è¾“å‡ºç‰¹å¾å›¾
    '''
        https://www.qianwen.com/share?shareId=512c5831-18ea-422d-93b1-0796cdf86588
    '''
    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            # X[i:i + h, j:j + w]ï¼šä»è¾“å…¥ X ä¸­åˆ‡å‡ºä¸å·ç§¯æ ¸ K åŒå°ºå¯¸çš„å­åŒºåŸŸï¼ˆæ„Ÿå—é‡ï¼‰
            # * Kï¼šé€å…ƒç´ ç›¸ä¹˜
            # .sum()ï¼šå¯¹æ‰€æœ‰å…ƒç´ æ±‚å’Œï¼Œå¾—åˆ°ä¸€ä¸ªæ ‡é‡ â†’ èµ‹å€¼ç»™ Y[i, j]
            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()
    return Y


X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])
Y = torch.tensor([[0.0, 1.0], [2.0, 3.0]])
corr2d(X, Y)


class Conv2D(nn.Module):
    def __init__(self, kernel_size):
        super().__init__()
        self.weight = nn.Parameter(torch.rand(kernel_size))
        self.bias = nn.Parameter(torch.zeros(1))

    def forward(self, x):
        return corr2d(x, self.weight) + self.bias


'''
6.2.3. å›¾åƒä¸­ç›®æ ‡çš„è¾¹ç¼˜æ£€æµ‹
å¦‚ä¸‹æ˜¯å·ç§¯å±‚çš„ä¸€ä¸ªç®€å•åº”ç”¨ï¼šé€šè¿‡æ‰¾åˆ°åƒç´ å˜åŒ–çš„ä½ç½®ï¼Œæ¥æ£€æµ‹å›¾åƒä¸­ä¸åŒé¢œè‰²çš„è¾¹ç¼˜ã€‚
'''
# é¦–å…ˆï¼Œæˆ‘ä»¬æ„é€ ä¸€ä¸ª6x8åƒç´ çš„é»‘ç™½å›¾åƒã€‚ä¸­é—´å››åˆ—ä¸ºé»‘è‰²ï¼ˆ0ï¼‰ï¼Œå…¶ä½™åƒç´ ä¸ºç™½è‰²ï¼ˆ1ï¼‰ã€‚
X = torch.ones((6, 8))
X[:, 2:6] = 0

# æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ„é€ ä¸€ä¸ªé«˜åº¦ä¸º1ã€å®½åº¦ä¸º2çš„å·ç§¯æ ¸Kã€‚å½“è¿›è¡Œäº’ç›¸å…³è¿ç®—æ—¶ï¼Œå¦‚æœæ°´å¹³ç›¸é‚»çš„ä¸¤å…ƒç´ ç›¸åŒï¼Œåˆ™è¾“å‡ºä¸ºé›¶ï¼Œå¦åˆ™è¾“å‡ºä¸ºéé›¶ã€‚
K = torch.tensor([[1.0, -1.0]])

Y = corr2d(X, K)

# å°†Xè¿›è¡Œè½¬ç½®ï¼Œåˆ™æ— æ³•åŒºåˆ†å¹³è¡Œè¾¹ç¼˜
# corr2d(X.t(), K)

'''
6.2.4. å­¦ä¹ å·ç§¯æ ¸
'''
# æ„é€ ä¸€ä¸ªäºŒç»´å·ç§¯å±‚ï¼Œå®ƒåŒ…å«ä¸€ä¸ªè¾“å‡ºé€šé“å’Œå½¢çŠ¶ä¸º(1, 2)çš„å·ç§¯æ ¸
'''
nn.Conv2d æ˜¯ PyTorch ä¸­ç”¨äºå®ç°äºŒç»´å·ç§¯æ“ä½œçš„æ ¸å¿ƒæ¨¡å—ï¼Œå¹¿æ³›åº”ç”¨äºå›¾åƒå¤„ç†ã€è®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼ˆå¦‚åˆ†ç±»ã€æ£€æµ‹ã€åˆ†å‰²ï¼‰ä¸­çš„ç‰¹å¾æå–ã€‚
å¯¹è¾“å…¥çš„å››ç»´å¼ é‡ï¼ˆé€šå¸¸æ˜¯å›¾åƒï¼‰æ‰§è¡Œ 2D å·ç§¯ï¼ˆå®é™…æ˜¯äº’ç›¸å…³ï¼‰ï¼Œé€šè¿‡å¯å­¦ä¹ çš„å·ç§¯æ ¸ï¼ˆæ»¤æ³¢å™¨ï¼‰æå–å±€éƒ¨ç©ºé—´ç‰¹å¾ã€‚
    âœ… è¾“å…¥å½¢çŠ¶ï¼š(N, C_in, H_in, W_in)
    âœ… è¾“å‡ºå½¢çŠ¶ï¼š(N, C_out, H_out, W_out)
    å‚æ•°ï¼š
        Nï¼šbatch size
        C_in / C_outï¼šè¾“å…¥/è¾“å‡ºé€šé“æ•°
        H, Wï¼šé«˜åº¦å’Œå®½åº¦
torch.nn.Conv2d(
    in_channels,
    out_channels,
    kernel_size,
    stride=1,
    padding=0,
    dilation=1,
    groups=1,
    bias=True,
    padding_mode='zeros',
    device=None,
    dtype=None
)
å‚æ•°	            ç±»å‹	                å¿…éœ€	é»˜è®¤å€¼	è¯´æ˜
in_channels	    int	                âœ…	â€”	    è¾“å…¥é€šé“æ•°ï¼ˆå¦‚ RGB å›¾åƒä¸º 3ï¼‰
out_channels	int	                âœ…	â€”	    è¾“å‡ºé€šé“æ•°ï¼ˆå³å·ç§¯æ ¸ä¸ªæ•°ï¼‰
kernel_size	    int or tuple	    âœ…	â€”	    å·ç§¯æ ¸å¤§å°ï¼Œå¦‚ 3 æˆ– (3, 5)
stride	        int or tuple	    âŒ	1	    å·ç§¯æ­¥é•¿
padding	        int or tuple or str	âŒ	0	    è¾¹ç•Œå¡«å……åƒç´ æ•°ï¼ˆæ”¯æŒ 'same', 'valid'ï¼‰
dilation	    int or tuple	    âŒ	1	    ç©ºæ´å·ç§¯è†¨èƒ€ç‡
groups	        int	                âŒ	1	    åˆ†ç»„å·ç§¯ï¼ˆgroups=in_channels â†’ æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼‰
bias	        bool                âŒ	True	æ˜¯å¦æ·»åŠ å¯å­¦ä¹ åç½®é¡¹
padding_mode	str	                âŒ	'zeros'	å¡«å……æ¨¡å¼ï¼š'zeros', 'reflect', 'replicate', 'circular'
'''
conv2d = nn.Conv2d(1, 1, kernel_size=(1, 2), bias=False)

X = X.reshape((1, 1, 6, 8))
Y = Y.reshape((1, 1, 6, 7))

lr = 3e-2

for i in range(20):
    Y_hat = conv2d(X)
    l = (Y_hat - Y) ** 2
    conv2d.zero_grad()
    l.sum().backward()
    conv2d.weight.data[:] -= lr * conv2d.weight.grad
    if (i + 1) % 2 == 0:
        print(f'epoch {i + 1}, loss {l.sum():.3f}')
# ç»å†10æ¬¡è¿­ä»£åè¯¯å·®å·²æ¥è¿‘æœ€ä½ï¼Œå·ç§¯æ ¸æƒé‡éå¸¸æ¥è¿‘æˆ‘ä»¬ä¹‹å‰å®šä¹‰çš„å·ç§¯æ ¸Kã€‚
# conv2d.weight.data.reshape((1, 2))


# ç»ƒä¹ 1ï¼šæ„å»ºä¸€ä¸ªå…·æœ‰å¯¹è§’çº¿è¾¹ç¼˜çš„å›¾åƒXã€‚
# å¦‚æœå°†æœ¬èŠ‚ä¸­ä¸¾ä¾‹çš„å·ç§¯æ ¸Kåº”ç”¨äºXï¼Œä¼šå‘ç”Ÿä»€ä¹ˆæƒ…å†µï¼Ÿ
#
# å¦‚æœè½¬ç½®Xä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ
#
# å¦‚æœè½¬ç½®Kä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ
X = torch.eye(8)
K = torch.tensor([[1.0, -1.0]])
Y = corr2d(X, K.t())
print(Y)
